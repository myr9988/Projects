{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aed619ee",
   "metadata": {},
   "source": [
    "### Problem:\n",
    "Sentiment analysis remains one of the key problems that has seen extensive application of natural language processing. This time around, given the tweets from customers about various tech firms who manufacture and sell mobiles, computers, laptops, etc, the task is to identify if the tweets have a negative sentiment towards such companies or products\n",
    "\n",
    "### Data\n",
    "train.csv - For training the models, we provide a labelled dataset of 7920 tweets. The dataset is provided in the form of a csv file with each line storing a tweet id, its label and the tweet.\n",
    "\n",
    "test.csv - The test data file contains only tweet ids and the tweet text with each tweet in a new line.\n",
    "\n",
    "Most profane and vulgar terms in the tweets have been replaced with “$&@*#”. However, please note that the dataset still might contain text that may be considered profane, vulgar, or offensive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d3cb30",
   "metadata": {},
   "source": [
    "### Importing Libraries & Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4378b80b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\SHREE\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\SHREE\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "\n",
    "train_data = pd.read_csv(r'C:\\Users\\SHREE\\Downloads\\Python CODES\\Customer Tweets Sentiment Analysis\\train.csv')\n",
    "test_data = pd.read_csv(r'C:\\Users\\SHREE\\Downloads\\Python CODES\\Customer Tweets Sentiment Analysis\\test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d7c67f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([train_data, test_data], axis=0)\n",
    "\n",
    "df = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81b5f2af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    5894\n",
       "1.0    2026\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc89025",
   "metadata": {},
   "source": [
    "### Creating functions to Remove URLs & Punctuations, Tokenizer, Stopword & Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fef892f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing URLs\n",
    "def remove_url(text):\n",
    "    return re.sub(r\"http\\S+\", \"\", text)\n",
    "\n",
    "#Removing Punctuations\n",
    "def remove_punct(text):\n",
    "    new_text = []\n",
    "    for t in text:\n",
    "        if t not in string.punctuation:\n",
    "            new_text.append(t)\n",
    "    return ''.join(new_text)\n",
    "\n",
    "\n",
    "#Tokenizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "\n",
    "\n",
    "#Removing Stop words\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def remove_sw(text):\n",
    "    new_text = []\n",
    "    for t in text:\n",
    "        if t not in stopwords.words('english'):\n",
    "            new_text.append(t)\n",
    "    return new_text\n",
    "\n",
    "#Lemmatizaion\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def word_lemmatizer(text):\n",
    "    new_text = []\n",
    "    for t in text:\n",
    "        lem_text = lemmatizer.lemmatize(t)\n",
    "        new_text.append(lem_text)\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4119cbff",
   "metadata": {},
   "source": [
    "### Applying the Functions to Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c2fd0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweet'] = df['tweet'].apply(lambda t: remove_url(t))\n",
    "\n",
    "df['tweet'] = df['tweet'].apply(lambda t: remove_punct(t))\n",
    "\n",
    "df['tweet'] = df['tweet'].apply(lambda t: tokenizer.tokenize(t.lower()))\n",
    "\n",
    "df['tweet'] = df['tweet'].apply(lambda t: remove_sw(t))\n",
    "\n",
    "df['tweet'] = df['tweet'].apply(lambda t: word_lemmatizer(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646bdd13",
   "metadata": {},
   "source": [
    "### Splitting the Data into Train & Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28806c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_set = df.copy()\n",
    "\n",
    "train_set = features_set.iloc[:len(train_data), :]\n",
    "\n",
    "test_set = features_set.iloc[len(train_data):, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66a045d",
   "metadata": {},
   "source": [
    "### Selecting Target & Feature Variables for Classifying Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "927d807b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_set['tweet']\n",
    "\n",
    "\n",
    "for i in range(0, len(X)):\n",
    "    X.iloc[i] = ' '.join(X.iloc[i])\n",
    "\n",
    "\n",
    "Y = train_set['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2cc508",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "597bbc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "TfidV = TfidfVectorizer()\n",
    "\n",
    "X = TfidV.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1540fd79",
   "metadata": {},
   "source": [
    "### Splitting the Data into Train & Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8c6618b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.1, random_state = 1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fce5b0f",
   "metadata": {},
   "source": [
    "### Model Selection & Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de6bf69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "lr.fit(x_train, y_train)\n",
    "\n",
    "y_predict_lr = lr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ccc8da7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8573232323232324"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "\n",
    "cm_lr = confusion_matrix(y_test, y_predict_lr)\n",
    "\n",
    "f1_lr = f1_score(y_test, y_predict_lr)\n",
    "\n",
    "score_lr = lr.score(x_test, y_test)\n",
    "score_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41e4ae0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(class_weight='balanced')\n",
    "\n",
    "rfc.fit(x_train, y_train)\n",
    "\n",
    "y_predict_rfc = rfc.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df7ba579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8813131313131313"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "\n",
    "cm_rfc = confusion_matrix(y_test, y_predict_rfc)\n",
    "\n",
    "f1_rfc = f1_score(y_test, y_predict_rfc)\n",
    "\n",
    "score_rfc = rfc.score(x_test, y_test)\n",
    "score_rfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45b69ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:10:18] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier(scale_pos_weight=3)\n",
    "\n",
    "xgb.fit(x_train, y_train)\n",
    "\n",
    "y_predict_xgb = xgb.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9cd54205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8762626262626263"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "\n",
    "cm_xgb = confusion_matrix(y_test, y_predict_xgb)\n",
    "\n",
    "f1_xgb = f1_score(y_test, y_predict_xgb)\n",
    "\n",
    "score_xgb = xgb.score(x_test, y_test)\n",
    "score_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1eeb4a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "lgb = LGBMClassifier(scale_pos_weight=3)\n",
    "\n",
    "#lgb.fit(X, Y)\n",
    "\n",
    "lgb.fit(x_train, y_train)\n",
    "\n",
    "y_predict_lgb = lgb.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f18d8194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8762626262626263"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "\n",
    "cm_lgb = confusion_matrix(y_test, y_predict_lgb)\n",
    "\n",
    "f1_lgb = f1_score(y_test, y_predict_lgb)\n",
    "\n",
    "score_lgb = lgb.score(x_test, y_test)\n",
    "score_lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16257b7",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "Here XGBoost & LightGBM Models are giving us High Accuracy with good F1 Score. We can use them for Classifying the Tweets as Positive Sentiment or Negative Sentiment Tweets towards such companies or products."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
